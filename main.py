import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score

# ---------------------------------------------------------------
# 1. Carregar dados reais (California Housing)
# ---------------------------------------------------------------
data = fetch_california_housing(as_frame=True)
X = data.data
y = data.target

print("‚úÖ Dataset carregado com sucesso!")
print("N√∫mero de amostras:", X.shape[0])
print("N√∫mero de atributos:", X.shape[1])
print()

# ---------------------------------------------------------------
# 2. Divis√£o em treino e teste
# ---------------------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ---------------------------------------------------------------
# 3. Normaliza√ß√£o
# ---------------------------------------------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ---------------------------------------------------------------
# 4. Modelos de Regress√£o
# ---------------------------------------------------------------
models = {
    "Linear Regression": LinearRegression(),
    "Ridge (L2)": Ridge(alpha=1.0),
    "Lasso (L1)": Lasso(alpha=0.1)
}

results = {}

# ---------------------------------------------------------------
# 5. Treinamento, Valida√ß√£o Cruzada e Avalia√ß√£o
# ---------------------------------------------------------------
for name, model in models.items():
    print(f"Treinando modelo: {name} ...")
    
    # Valida√ß√£o cruzada
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
    
    # Treinamento
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    
    # M√©tricas
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    
    results[name] = {
        "Modelo": model,
        "R¬≤ teste": r2,
        "MSE teste": mse,
        "R¬≤ CV (m√©dio)": cv_scores.mean(),
        "Predi√ß√µes": y_pred
    }

# ---------------------------------------------------------------
# 6. Resultados num√©ricos
# ---------------------------------------------------------------
df_results = pd.DataFrame(results).T.drop(columns=["Modelo", "Predi√ß√µes"])
print("\nüìä Resultados de desempenho:\n")
print(df_results.round(4))
print()

# ---------------------------------------------------------------
# 7. Visualiza√ß√£o: Compara√ß√£o geral dos modelos
# ---------------------------------------------------------------
plt.figure(figsize=(10, 5))
plt.bar(df_results.index, df_results["R¬≤ teste"], color=['#4CAF50', '#2196F3', '#FF9800'])
plt.title("Compara√ß√£o de desempenho entre modelos (R¬≤ no teste)")
plt.ylabel("R¬≤")
plt.show()

# ---------------------------------------------------------------
# 8. Visualiza√ß√£o: Real vs Predito (todos os modelos)
# ---------------------------------------------------------------
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

for ax, (name, info) in zip(axes, results.items()):
    y_pred = info["Predi√ß√µes"]
    ax.scatter(y_test, y_pred, alpha=0.6)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', lw=2)
    ax.set_title(name)
    ax.set_xlabel("Valores reais")
    ax.set_ylabel("Valores preditos")

plt.suptitle("Compara√ß√£o: Valores Reais vs Preditos para cada modelo", fontsize=14)
plt.tight_layout()
plt.show()

# ---------------------------------------------------------------
# 9. Identificar e exibir o melhor modelo
# ---------------------------------------------------------------
best_model_name = df_results["R¬≤ teste"].idxmax()
best_model_info = results[best_model_name]
best_r2 = best_model_info["R¬≤ teste"]
best_mse = best_model_info["MSE teste"]
best_cv = best_model_info["R¬≤ CV (m√©dio)"]

print("üèÜ MELHOR MODELO ENCONTRADO üèÜ")
print(f"Modelo: {best_model_name}")
print(f"R¬≤ no teste: {best_r2:.4f}")
print(f"MSE no teste: {best_mse:.4f}")
print(f"R¬≤ m√©dio (valida√ß√£o cruzada): {best_cv:.4f}")
print()

# ---------------------------------------------------------------
# 10. Visualiza√ß√£o: Gr√°fico do melhor modelo
# ---------------------------------------------------------------
plt.figure(figsize=(6, 6))
plt.scatter(y_test, best_model_info["Predi√ß√µes"], alpha=0.6, color="#4CAF50")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', lw=2)
plt.title(f"Real vs Predito ‚Äî {best_model_name}")
plt.xlabel("Valores reais")
plt.ylabel("Valores preditos")
plt.show()
